{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "np.random.seed(30)\n",
    "rn.seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9893163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GRU, Conv3D, MaxPooling3D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83ee114",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/datasets/Project_data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a3ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CSV Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WIN_20180925_17_08_43_Pro_Left_Swipe_new;Left_Swipe_new;0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_17_18_28_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180925_17_18_56_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20180925_17_19_51_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WIN_20180925_17_20_14_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WIN_20180925_17_21_28_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WIN_20180925_17_08_43_Pro_Left_Swipe_new;Left_Swipe_new;0\n",
       "0  WIN_20180925_17_18_28_Pro_Left_Swipe_new;Left_...       \n",
       "1  WIN_20180925_17_18_56_Pro_Left_Swipe_new;Left_...       \n",
       "2  WIN_20180925_17_19_51_Pro_Left_Swipe_new;Left_...       \n",
       "3  WIN_20180925_17_20_14_Pro_Left_Swipe_new;Left_...       \n",
       "4  WIN_20180925_17_21_28_Pro_Left_Swipe_new;Left_...       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CSV Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WIN_20180925_17_17_04_Pro_Left_Swipe_new;Left_Swipe_new;0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_17_43_01_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180925_18_01_40_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20180925_18_03_21_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WIN_20180926_16_46_22_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WIN_20180926_16_47_09_Pro_Left_Swipe_new;Left_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WIN_20180925_17_17_04_Pro_Left_Swipe_new;Left_Swipe_new;0\n",
       "0  WIN_20180925_17_43_01_Pro_Left_Swipe_new;Left_...       \n",
       "1  WIN_20180925_18_01_40_Pro_Left_Swipe_new;Left_...       \n",
       "2  WIN_20180925_18_03_21_Pro_Left_Swipe_new;Left_...       \n",
       "3  WIN_20180926_16_46_22_Pro_Left_Swipe_new;Left_...       \n",
       "4  WIN_20180926_16_47_09_Pro_Left_Swipe_new;Left_...       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(os.path.join(base_dir, 'train.csv'))\n",
    "val_csv = pd.read_csv(os.path.join(base_dir, 'val.csv'))\n",
    "\n",
    "print(\"Train CSV Sample:\")\n",
    "display(train_csv.head())\n",
    "print(\"Validation CSV Sample:\")\n",
    "display(val_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f00b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('/home/datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/home/datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bdab47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size, img_size=(100, 100), num_classes=5):\n",
    "    print('Source path =', source_path, '; batch size =', batch_size)\n",
    "    \n",
    "    img_idx = list(range(30))\n",
    "    x = len(img_idx)\n",
    "    y, z = img_size\n",
    "    \n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(t) // batch_size\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            batch_data = np.zeros((batch_size, x, y, z, 3))\n",
    "            batch_labels = np.zeros((batch_size, num_classes))\n",
    "\n",
    "            for folder in range(batch_size):\n",
    "                folder_name = t[folder + (batch * batch_size)].strip().split(';')[0]\n",
    "                folder_path = os.path.join(source_path, folder_name)\n",
    "                imgs = sorted(os.listdir(folder_path))\n",
    "                \n",
    "                for idx, item in enumerate(img_idx):\n",
    "                    img_path = os.path.join(folder_path, imgs[item])\n",
    "                    image = Image.open(img_path).resize((y, z))\n",
    "                    image_array = np.array(image).astype(np.float32) / 255.0\n",
    "                    if image_array.shape[-1] == 3:\n",
    "                        batch_data[folder, idx, :, :, :] = image_array\n",
    "                    else:\n",
    "                        batch_data[folder, idx, :, :, :] = np.stack([image_array]*3, axis=-1)\n",
    "                \n",
    "                label = int(t[folder + (batch * batch_size)].strip().split(';')[2])\n",
    "                batch_labels[folder] = to_categorical(label, num_classes=num_classes)\n",
    "            \n",
    "            yield batch_data, batch_labels\n",
    "\n",
    "        if len(t) % batch_size != 0:\n",
    "            remaining_size = len(t) % batch_size\n",
    "            batch_data = np.zeros((remaining_size, x, y, z, 3))\n",
    "            batch_labels = np.zeros((remaining_size, num_classes))\n",
    "            \n",
    "            for folder in range(remaining_size):\n",
    "                folder_name = t[folder + (num_batches * batch_size)].strip().split(';')[0]\n",
    "                folder_path = os.path.join(source_path, folder_name)\n",
    "                imgs = sorted(os.listdir(folder_path))\n",
    "                \n",
    "                for idx, item in enumerate(img_idx):\n",
    "                    img_path = os.path.join(folder_path, imgs[item])\n",
    "                    image = Image.open(img_path).resize((y, z))\n",
    "                    image_array = np.array(image).astype(np.float32) / 255.0\n",
    "                    if image_array.shape[-1] == 3:\n",
    "                        batch_data[folder, idx, :, :, :] = image_array\n",
    "                    else:\n",
    "                        batch_data[folder, idx, :, :, :] = np.stack([image_array]*3, axis=-1)\n",
    "                \n",
    "                label = int(t[folder + (num_batches * batch_size)].strip().split(';')[2])\n",
    "                batch_labels[folder] = to_categorical(label, num_classes=num_classes)\n",
    "            \n",
    "            yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c56e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "Current Date and Time: 2024-11-05 19:33:34.802206\n"
     ]
    }
   ],
   "source": [
    "train_path = '/home/datasets/Project_data/train'\n",
    "val_path = '/home/datasets/Project_data/val'\n",
    "\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "\n",
    "num_epochs = 20\n",
    "print('# epochs =', num_epochs)\n",
    "\n",
    "curr_dt_time = datetime.datetime.now()\n",
    "print(\"Current Date and Time:\", curr_dt_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccf482be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 19:34:42.615444: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-11-05 19:34:42.615507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14800 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:3f:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_conv3d_model(input_shape=(30, 100, 100, 3), num_classes=5):\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (30, 100, 100, 3)\n",
    "num_classes = 5\n",
    "conv3d_model = create_conv3d_model(input_shape=input_shape, num_classes=num_classes)\n",
    "conv3d_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "362f8876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 28, 98, 98, 32)    2624      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 14, 49, 49, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 49, 49, 32)   128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 12, 47, 47, 64)    55360     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 23, 23, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 6, 23, 23, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 4, 21, 21, 128)    221312    \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 2, 10, 10, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2, 10, 10, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6553856   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,835,333\n",
      "Trainable params: 6,834,885\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimiser = Adam(learning_rate=0.001)\n",
    "\n",
    "model = conv3d_model\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8dcc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b312f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ', '').replace(':', '_') + '/'\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "callbacks_list = [checkpoint, LR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d0ac711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 42\n",
      "Validation steps: 7\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences % batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences / batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences // batch_size) + 1\n",
    "\n",
    "if (num_val_sequences % batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences / batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences // batch_size) + 1\n",
    "\n",
    "print(\"Steps per epoch:\", steps_per_epoch)\n",
    "print(\"Validation steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67dedc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = /home/datasets/Project_data/train ; batch size = 16\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 19:40:16.000950: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 3.9513 - categorical_accuracy: 0.5083Source path = /home/datasets/Project_data/val ; batch size = 16\n",
      "\n",
      "Epoch 00001: saving model to model_init_2024-11-0519_33_34.802206/model-00001-3.95125-0.50830-28.39872-0.18000.h5\n",
      "42/42 [==============================] - 68s 2s/step - loss: 3.9513 - categorical_accuracy: 0.5083 - val_loss: 28.3987 - val_categorical_accuracy: 0.1800 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2176 - categorical_accuracy: 0.6471\n",
      "Epoch 00002: saving model to model_init_2024-11-0519_33_34.802206/model-00002-2.21761-0.64706-8.40900-0.18000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 2.2176 - categorical_accuracy: 0.6471 - val_loss: 8.4090 - val_categorical_accuracy: 0.1800 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2412 - categorical_accuracy: 0.7436\n",
      "Epoch 00003: saving model to model_init_2024-11-0519_33_34.802206/model-00003-1.24125-0.74359-6.95101-0.30000.h5\n",
      "42/42 [==============================] - 65s 2s/step - loss: 1.2412 - categorical_accuracy: 0.7436 - val_loss: 6.9510 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.8647 - categorical_accuracy: 0.7662\n",
      "Epoch 00004: saving model to model_init_2024-11-0519_33_34.802206/model-00004-0.86470-0.76621-4.92441-0.41000.h5\n",
      "42/42 [==============================] - 65s 2s/step - loss: 0.8647 - categorical_accuracy: 0.7662 - val_loss: 4.9244 - val_categorical_accuracy: 0.4100 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6353 - categorical_accuracy: 0.8401\n",
      "Epoch 00005: saving model to model_init_2024-11-0519_33_34.802206/model-00005-0.63529-0.84012-4.04323-0.47000.h5\n",
      "42/42 [==============================] - 63s 2s/step - loss: 0.6353 - categorical_accuracy: 0.8401 - val_loss: 4.0432 - val_categorical_accuracy: 0.4700 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6104 - categorical_accuracy: 0.8296\n",
      "Epoch 00006: saving model to model_init_2024-11-0519_33_34.802206/model-00006-0.61042-0.82956-6.10331-0.36000.h5\n",
      "42/42 [==============================] - 63s 2s/step - loss: 0.6104 - categorical_accuracy: 0.8296 - val_loss: 6.1033 - val_categorical_accuracy: 0.3600 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.5146 - categorical_accuracy: 0.8658\n",
      "Epoch 00007: saving model to model_init_2024-11-0519_33_34.802206/model-00007-0.51459-0.86576-3.84106-0.47000.h5\n",
      "42/42 [==============================] - 63s 2s/step - loss: 0.5146 - categorical_accuracy: 0.8658 - val_loss: 3.8411 - val_categorical_accuracy: 0.4700 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9641 - categorical_accuracy: 0.8190\n",
      "Epoch 00008: saving model to model_init_2024-11-0519_33_34.802206/model-00008-0.96413-0.81900-8.43074-0.40000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.9641 - categorical_accuracy: 0.8190 - val_loss: 8.4307 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3357 - categorical_accuracy: 0.8929\n",
      "Epoch 00009: saving model to model_init_2024-11-0519_33_34.802206/model-00009-0.33569-0.89291-1.39898-0.69000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.3357 - categorical_accuracy: 0.8929 - val_loss: 1.3990 - val_categorical_accuracy: 0.6900 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.5576 - categorical_accuracy: 0.8597\n",
      "Epoch 00010: saving model to model_init_2024-11-0519_33_34.802206/model-00010-0.55761-0.85973-1.82428-0.64000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.5576 - categorical_accuracy: 0.8597 - val_loss: 1.8243 - val_categorical_accuracy: 0.6400 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3918 - categorical_accuracy: 0.9005\n",
      "Epoch 00011: saving model to model_init_2024-11-0519_33_34.802206/model-00011-0.39178-0.90045-1.28556-0.76000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.3918 - categorical_accuracy: 0.9005 - val_loss: 1.2856 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3666 - categorical_accuracy: 0.9005\n",
      "Epoch 00012: saving model to model_init_2024-11-0519_33_34.802206/model-00012-0.36657-0.90045-3.66464-0.60000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.3666 - categorical_accuracy: 0.9005 - val_loss: 3.6646 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2818 - categorical_accuracy: 0.9140\n",
      "Epoch 00013: saving model to model_init_2024-11-0519_33_34.802206/model-00013-0.28181-0.91403-3.00616-0.71000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.2818 - categorical_accuracy: 0.9140 - val_loss: 3.0062 - val_categorical_accuracy: 0.7100 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2893 - categorical_accuracy: 0.9140\n",
      "Epoch 00014: saving model to model_init_2024-11-0519_33_34.802206/model-00014-0.28926-0.91403-3.05967-0.60000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "42/42 [==============================] - 62s 2s/step - loss: 0.2893 - categorical_accuracy: 0.9140 - val_loss: 3.0597 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1489 - categorical_accuracy: 0.9487\n",
      "Epoch 00015: saving model to model_init_2024-11-0519_33_34.802206/model-00015-0.14891-0.94872-0.69254-0.85000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.1489 - categorical_accuracy: 0.9487 - val_loss: 0.6925 - val_categorical_accuracy: 0.8500 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0813 - categorical_accuracy: 0.9653\n",
      "Epoch 00016: saving model to model_init_2024-11-0519_33_34.802206/model-00016-0.08131-0.96531-0.28781-0.91000.h5\n",
      "42/42 [==============================] - 64s 2s/step - loss: 0.0813 - categorical_accuracy: 0.9653 - val_loss: 0.2878 - val_categorical_accuracy: 0.9100 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0861 - categorical_accuracy: 0.9729\n",
      "Epoch 00017: saving model to model_init_2024-11-0519_33_34.802206/model-00017-0.08613-0.97285-0.45453-0.88000.h5\n",
      "42/42 [==============================] - 61s 1s/step - loss: 0.0861 - categorical_accuracy: 0.9729 - val_loss: 0.4545 - val_categorical_accuracy: 0.8800 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0684 - categorical_accuracy: 0.9774\n",
      "Epoch 00018: saving model to model_init_2024-11-0519_33_34.802206/model-00018-0.06838-0.97738-0.31201-0.90000.h5\n",
      "42/42 [==============================] - 60s 1s/step - loss: 0.0684 - categorical_accuracy: 0.9774 - val_loss: 0.3120 - val_categorical_accuracy: 0.9000 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0773 - categorical_accuracy: 0.9759\n",
      "Epoch 00019: saving model to model_init_2024-11-0519_33_34.802206/model-00019-0.07729-0.97587-0.42035-0.87000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "42/42 [==============================] - 59s 1s/step - loss: 0.0773 - categorical_accuracy: 0.9759 - val_loss: 0.4204 - val_categorical_accuracy: 0.8700 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0516 - categorical_accuracy: 0.9804\n",
      "Epoch 00020: saving model to model_init_2024-11-0519_33_34.802206/model-00020-0.05163-0.98039-0.56491-0.86000.h5\n",
      "42/42 [==============================] - 60s 1s/step - loss: 0.0516 - categorical_accuracy: 0.9804 - val_loss: 0.5649 - val_categorical_accuracy: 0.8600 - lr: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3abcf1ca0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=None,\n",
    "    workers=1,\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e3c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cc3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6a7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
